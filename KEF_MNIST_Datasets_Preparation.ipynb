{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup for KMNIST, EMNIST, FashionMNIST"
      ],
      "metadata": {
        "id": "liScBOPLtHph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install idx2numpy"
      ],
      "metadata": {
        "id": "ktDHuuy6JnH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import idx2numpy\n",
        "import gzip\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "JKIsvM6yuzYW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"./data\", exist_ok=True)\n",
        "os.makedirs(\"./data/K49\", exist_ok=True)\n",
        "os.makedirs(\"./data/EMNIST\", exist_ok=True)\n",
        "os.makedirs(\"./data/FashionMNIST\", exist_ok=True)"
      ],
      "metadata": {
        "id": "_pWWZwTiP_1w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the raw K49, EMNIST, and FashionMNIST datasets"
      ],
      "metadata": {
        "id": "NRwSTo6YGIIP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download K49"
      ],
      "metadata": {
        "id": "XCFx1CTMPCpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_list = ['http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-imgs.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-labels.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-imgs.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-labels.npz']\n",
        "\n",
        "for url in url_list:\n",
        "    path = url.split('/')[-1]\n",
        "    r = requests.get(url, stream=True)\n",
        "    with open(path, 'wb') as f:\n",
        "        total_length = int(r.headers.get('content-length'))\n",
        "        print('Downloading {} - {:.1f} MB'.format(path, (total_length / 1024000)))\n",
        "\n",
        "        for chunk in tqdm(r.iter_content(chunk_size=1024), total=int(total_length / 1024) + 1, unit=\"KB\"):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "print('All dataset files downloaded!')\n",
        "\n",
        "filenames = {'k49-train-imgs': (\"train\", \"X.pt\"),\n",
        "             'k49-train-labels': (\"train\", \"y.pt\"),\n",
        "             'k49-test-imgs': (\"test\", \"X.pt\"),\n",
        "             'k49-test-labels': (\"test\", \"y.pt\")}\n",
        "\n",
        "for filename in filenames.keys():\n",
        "    with zipfile.ZipFile(\"./{}.npz\".format(filename), 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"./{}-extracted\".format(filename))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zY4I2Q4xiSD",
        "outputId": "be34faca-fd90-4d56-dab4-823d74f73d22"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading k49-train-imgs.npz - 64.6 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64569/64569 [01:23<00:00, 777.38KB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading k49-train-labels.npz - 0.2 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 161/161 [00:00<00:00, 178.99KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading k49-test-imgs.npz - 10.7 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10715/10715 [00:17<00:00, 601.19KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading k49-test-labels.npz - 0.0 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 123.42KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dataset files downloaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download EMNIST"
      ],
      "metadata": {
        "id": "Bm3dZXGDPGDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_list = ['https://biometrics.nist.gov/cs_links/EMNIST/gzip.zip']\n",
        "\n",
        "for url in url_list:\n",
        "    path = url.split('/')[-1]\n",
        "    r = requests.get(url, stream=True)\n",
        "    with open(path, 'wb') as f:\n",
        "        total_length = int(r.headers.get('content-length'))\n",
        "        print('Downloading {} - {:.1f} MB'.format(path, (total_length / 1024000)))\n",
        "\n",
        "        for chunk in tqdm(r.iter_content(chunk_size=1024), total=int(total_length / 1024) + 1, unit=\"KB\"):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "print('All dataset files downloaded!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkehjfaRy6yx",
        "outputId": "bfbeff85-7c26-4596-81aa-6fd74856e423"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading gzip.zip - 548.6 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 548588/548588 [00:15<00:00, 35463.76KB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dataset files downloaded!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(\"./gzip.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./EMNIST-extracted\")"
      ],
      "metadata": {
        "id": "5hS-VszLz714"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Fashion MNIST"
      ],
      "metadata": {
        "id": "ZCR-iD1OMcrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_list = [\n",
        "    'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-labels-idx1-ubyte.gz',\n",
        "    'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-images-idx3-ubyte.gz',\n",
        "    'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-labels-idx1-ubyte.gz',\n",
        "    'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-images-idx3-ubyte.gz'\n",
        "]\n",
        "\n",
        "for url in url_list:\n",
        "    path = url.split('/')[-1]\n",
        "    r = requests.get(url, stream=True)\n",
        "    with open(path, 'wb') as f:\n",
        "        total_length = int(r.headers.get('content-length'))\n",
        "        print('Downloading {} - {:.1f} MB'.format(path, (total_length / 1024000)))\n",
        "\n",
        "        for chunk in tqdm(r.iter_content(chunk_size=1024), total=int(total_length / 1024) + 1, unit=\"KB\"):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "print('All dataset files downloaded!')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ctQUrpQJ1yz",
        "outputId": "1bb03c91-3296-4dff-8a36-bf626351d45f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading t10k-labels-idx1-ubyte.gz - 0.0 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 8870.58KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading t10k-images-idx3-ubyte.gz - 4.3 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4319/4319 [00:00<00:00, 40716.18KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading train-labels-idx1-ubyte.gz - 0.0 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 13401.81KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading train-images-idx3-ubyte.gz - 25.8 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25803/25803 [00:00<00:00, 45313.25KB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dataset files downloaded!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process and Save Splits for All MNIST Datasets"
      ],
      "metadata": {
        "id": "6K84f9GYGx-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(X_train, y_train, X_test, y_test):\n",
        "    print(X_train.shape)\n",
        "    print(X_train.mean())\n",
        "    print(X_train.std())\n",
        "\n",
        "    # Calculate mean and standard deviation for each channel\n",
        "    mean = X_train.mean(axis=(1,2)).sum(0) / X_train.shape[0]\n",
        "    std = X_train.std(axis=(1,2)).sum(0) / X_train.shape[0]\n",
        "\n",
        "    transform_mean = [mean, mean, mean]\n",
        "    transform_std =  [std, std, std]\n",
        "\n",
        "    X_train, X_test = X_train.unsqueeze(1), X_test.unsqueeze(1)\n",
        "    X_train = torch.cat((X_train, X_train, X_train), dim=1)\n",
        "    X_test = torch.cat((X_test, X_test, X_test), dim=1)\n",
        "\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Normalize(mean = transform_mean, std = transform_std),\n",
        "    ])\n",
        "\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Normalize(mean = transform_mean, std = transform_std),\n",
        "    ])\n",
        "\n",
        "    return train_transform(X_train), y_train, val_transform(X_test), y_test\n",
        "\n",
        "### Split training set into train and validation sets\n",
        "def split_dataset(X: torch.Tensor, y: torch.Tensor):\n",
        "    torch.manual_seed(0)\n",
        "    splitnum = math.floor(X.size()[0]*0.1)\n",
        "    indices = torch.randperm(X.size()[0])\n",
        "    X = X[indices]\n",
        "    y = y[indices]\n",
        "    X_val = X[:splitnum].clone().detach()\n",
        "    y_val = y[:splitnum].clone().detach()\n",
        "    X_train = X[splitnum:].clone().detach()\n",
        "    y_train = y[splitnum:].clone().detach()\n",
        "    print(\"trainsplit size: \", X_train.size(), \" valsplit size: \", X_val.size())\n",
        "\n",
        "    return X_train, y_train, X_val, y_val"
      ],
      "metadata": {
        "id": "5lxbRI4x1rNf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process Kuzushiji-49 MNIST Splits"
      ],
      "metadata": {
        "id": "NBaQbMKEObv2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUG7eEiBXwpc",
        "outputId": "f4bb9ca5-b1a5-4473-c12d-fa488bba21e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([232365, 28, 28])\n",
            "tensor(45.9159)\n",
            "tensor(87.2451)\n",
            "trainsplit size:  torch.Size([209129, 3, 28, 28])  valsplit size:  torch.Size([23236, 3, 28, 28])\n",
            "X resulting mean -0.00012973950651939958 and std 1.0398712158203125\n",
            "X resulting mean 0.0011669847881421447 and std 1.0409965515136719\n",
            "X resulting mean -0.01778692752122879 and std 1.02264404296875\n"
          ]
        }
      ],
      "source": [
        "filenames = {'X_train': \"./k49-train-imgs-extracted/arr_0.npy\",\n",
        "             'y_train': \"./k49-train-labels-extracted/arr_0.npy\",\n",
        "             'X_test': \"./k49-test-imgs-extracted/arr_0.npy\",\n",
        "             'y_test': \"./k49-test-labels-extracted/arr_0.npy\"}\n",
        "\n",
        "X_train = np.load(filenames[\"X_train\"])\n",
        "y_train = np.load(filenames[\"y_train\"])\n",
        "X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)\n",
        "\n",
        "X_test = np.load(filenames[\"X_test\"])\n",
        "y_test = np.load(filenames[\"y_test\"])\n",
        "X_test, y_test = torch.from_numpy(X_test).float(), torch.from_numpy(y_test)\n",
        "\n",
        "\n",
        "X_train, y_train, X_test, y_test = prepare_data(X_train, y_train, X_test, y_test)\n",
        "X_train, y_train, X_valid, y_valid = split_dataset(X_train, y_train)\n",
        "\n",
        "for x in X_train, X_valid, X_test:\n",
        "    print(\"X resulting mean {} and std {}\".format(x.mean(), x.std()))\n",
        "\n",
        "os.makedirs(\"./data/K49/train\", exist_ok=True)\n",
        "os.makedirs(\"./data/K49/valid\", exist_ok=True)\n",
        "os.makedirs(\"./data/K49/test\", exist_ok=True)\n",
        "\n",
        "torch.save(X_train, \"./data/K49/train/X.pt\")\n",
        "torch.save(y_train, \"./data/K49/train/y.pt\")\n",
        "torch.save(X_valid, \"./data/K49/valid/X.pt\")\n",
        "torch.save(y_valid, \"./data/K49/valid/y.pt\")\n",
        "torch.save(X_test, \"./data/K49/test/X.pt\")\n",
        "torch.save(y_test, \"./data/K49/test/y.pt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process the Extended MNIST - Balanced Splits"
      ],
      "metadata": {
        "id": "Hkh6rcuyG079"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with gzip.open(\"./EMNIST-extracted/gzip/emnist-balanced-train-images-idx3-ubyte.gz\", 'rb') as f:\n",
        "    X_train = idx2numpy.convert_from_file(f)\n",
        "with gzip.open(\"./EMNIST-extracted/gzip/emnist-balanced-train-labels-idx1-ubyte.gz\", 'rb') as f:\n",
        "    y_train = idx2numpy.convert_from_file(f)\n",
        "with gzip.open(\"./EMNIST-extracted/gzip/emnist-balanced-test-images-idx3-ubyte.gz\", 'rb') as f:\n",
        "    X_test = idx2numpy.convert_from_file(f)\n",
        "with gzip.open(\"./EMNIST-extracted/gzip/emnist-balanced-test-labels-idx1-ubyte.gz\", 'rb') as f:\n",
        "    y_test = idx2numpy.convert_from_file(f)\n",
        "\n",
        "\n",
        "X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)\n",
        "X_test, y_test = torch.from_numpy(X_test).float(), torch.from_numpy(y_test)\n",
        "\n",
        "X_train, y_train, X_test, y_test = prepare_data(X_train, y_train, X_test, y_test)\n",
        "X_train, y_train, X_valid, y_valid = split_dataset(X_train, y_train)\n",
        "\n",
        "for x in X_train, X_valid, X_test:\n",
        "    print(\"X resulting mean {} and std {}\".format(x.mean(), x.std()))\n",
        "\n",
        "os.makedirs(\"./data/EMNIST/train\", exist_ok=True)\n",
        "os.makedirs(\"./data/EMNIST/valid\", exist_ok=True)\n",
        "os.makedirs(\"./data/EMNIST/test\", exist_ok=True)\n",
        "\n",
        "torch.save(X_train, \"./data/EMNIST/train/X.pt\")\n",
        "torch.save(y_train, \"./data/EMNIST/train/y.pt\")\n",
        "torch.save(X_valid, \"./data/EMNIST/valid/X.pt\")\n",
        "torch.save(y_valid, \"./data/EMNIST/valid/y.pt\")\n",
        "torch.save(X_test, \"./data/EMNIST/test/X.pt\")\n",
        "torch.save(y_test, \"./data/EMNIST/test/y.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqa_KXTSBSP5",
        "outputId": "4b5b2eb9-cba4-4270-abfd-da749fc105f3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-815990750.py:11: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([112800, 28, 28])\n",
            "tensor(44.6516)\n",
            "tensor(84.9755)\n",
            "trainsplit size:  torch.Size([101520, 3, 28, 28])  valsplit size:  torch.Size([11280, 3, 28, 28])\n",
            "X resulting mean 7.095682667568326e-05 and std 1.020035743713379\n",
            "X resulting mean -0.0006388546316884458 and std 1.019400715827942\n",
            "X resulting mean 0.001280162250623107 and std 1.0206949710845947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process and save FashionMNIST splits"
      ],
      "metadata": {
        "id": "Xl4gD5AkG6De"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gzip.open(\"./train-images-idx3-ubyte.gz\", 'rb') as f:\n",
        "    X_train = idx2numpy.convert_from_file(f)\n",
        "with gzip.open(\"./train-labels-idx1-ubyte.gz\", 'rb') as f:\n",
        "    y_train = idx2numpy.convert_from_file(f)\n",
        "with gzip.open(\"./t10k-images-idx3-ubyte.gz\", 'rb') as f:\n",
        "    X_test = idx2numpy.convert_from_file(f)\n",
        "with gzip.open(\"./t10k-labels-idx1-ubyte.gz\", 'rb') as f:\n",
        "    y_test = idx2numpy.convert_from_file(f)\n",
        "\n",
        "X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)\n",
        "X_test, y_test = torch.from_numpy(X_test).float(), torch.from_numpy(y_test)\n",
        "\n",
        "X_train, y_train, X_test, y_test = prepare_data(X_train, y_train, X_test, y_test)\n",
        "X_train, y_train, X_valid, y_valid = split_dataset(X_train, y_train)\n",
        "\n",
        "for x in X_train, X_valid, X_test:\n",
        "    print(\"X resulting mean {} and std {}\".format(x.mean(), x.std()))\n",
        "\n",
        "\n",
        "os.makedirs(\"./data/FashionMNIST/train\", exist_ok=True)\n",
        "os.makedirs(\"./data/FashionMNIST/valid\", exist_ok=True)\n",
        "os.makedirs(\"./data/FashionMNIST/test\", exist_ok=True)\n",
        "\n",
        "torch.save(X_train, \"./data/FashionMNIST/train/X.pt\")\n",
        "torch.save(y_train, \"./data/FashionMNIST/train/y.pt\")\n",
        "torch.save(X_valid, \"./data/FashionMNIST/valid/X.pt\")\n",
        "torch.save(y_valid, \"./data/FashionMNIST/valid/y.pt\")\n",
        "torch.save(X_test, \"./data/FashionMNIST/test/X.pt\")\n",
        "torch.save(y_test, \"./data/FashionMNIST/test/y.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8HClgiGLQSO",
        "outputId": "7822e69f-5e22-4cc6-b740-f3e618d0e137"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "tensor(72.9404)\n",
            "tensor(90.0212)\n",
            "trainsplit size:  torch.Size([54000, 3, 28, 28])  valsplit size:  torch.Size([6000, 3, 28, 28])\n",
            "X resulting mean -0.0005339629133231938 and std 1.101234793663025\n",
            "X resulting mean 0.004804421681910753 and std 1.105269432067871\n",
            "X resulting mean 0.0025234385393559933 and std 1.099829912185669\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}